{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "52bfbfde1bba170d2347810de8f6889029c040f7"
   },
   "source": [
    "# &#128204; Intro Of This Notebook\n",
    "The aim of this study is to diagnose epileptic seizures by using different machine learning algorithms. For this purpose, the frequency components of the EEG are extracted by using the discrete wavelet transform (DWT) and parametric  methods based on autoregressive (AR) model. Both these two feature extraction methods are applied to the input of machine learning classification algorithms such as Artificial Neural Networks (ANN), Naive Bayesian, k-Nearest Neighbor (k-NN), Support Vector Machines (SVM), Logistic Regression,Principal Component Analysis. The results show that k-NN, ANN and SVM were the most efficient method according to test processing of both DWT and AR as feature extraction for recognition of epileptic seizures in EEG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "6c2af32ca322bdd0686e244dd10fbb248409c7a1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "@import url('https://fonts.googleapis.com/css?family=Ewert|Roboto&effect=3d|ice|');\n",
       "body {background-color: gainsboro;} \n",
       "a {color: #37c9e1; font-family: 'Roboto';} \n",
       "h1 {color: #37c9e1; font-family: 'Orbitron'; text-shadow: 4px 4px 4px #aaa;} \n",
       "h2, h3 {color: slategray; font-family: 'Orbitron'; text-shadow: 4px 4px 4px #aaa;}\n",
       "h4 {color: #818286; font-family: 'Roboto';}\n",
       "span {font-family:'Roboto'; color:black; text-shadow: 5px 5px 5px #aaa;}  \n",
       "div.output_area pre{font-family:'Roboto'; font-size:110%; color:lightblue;}      \n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "@import url('https://fonts.googleapis.com/css?family=Ewert|Roboto&effect=3d|ice|');\n",
    "body {background-color: gainsboro;} \n",
    "a {color: #37c9e1; font-family: 'Roboto';} \n",
    "h1 {color: #37c9e1; font-family: 'Orbitron'; text-shadow: 4px 4px 4px #aaa;} \n",
    "h2, h3 {color: slategray; font-family: 'Orbitron'; text-shadow: 4px 4px 4px #aaa;}\n",
    "h4 {color: #818286; font-family: 'Roboto';}\n",
    "span {font-family:'Roboto'; color:black; text-shadow: 5px 5px 5px #aaa;}  \n",
    "div.output_area pre{font-family:'Roboto'; font-size:110%; color:lightblue;}      \n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# &#128225; Introduction Of Epileptic\n",
    "Epilepsy is a serious brain illness that is an endemic neurological disorder all over  the world. It is a clinical result that occurs with abnormal neurological electrical  discharging of brain. Epileptic seizures represent the most common positive signs and  symptoms of brain disturbance, and epilepsy is one of the most common primary  brain disorders . Vascular causes, traumatic causes, infections and brain abscesses,  brain tumors, nutritional deficiencies, pyridoxine deficiency, calcium metabolism  disorders are lead causes for epilepsy. For in diagnosing epilepsy, research is needed  for better understanding of mechanisms causing epileptic disorders. The evaluation  and treatment of neurophysiologic disorders are diagnosed with the  electroencephalogram [EEG]. EEG is crucial for accurate classification of different  forms of epilepsy ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "source": [
    "# Theoretical Background\n",
    "The aim of this study is to contribute to the diagnosis of epilepsy by taking advantage of the engineering. So, for diagnosing of epileptic seizures from EEG signals are transformed discrete wavelet and auto regressive models. After these transformations, extract data is applied input for Back-propagation, Naive Bayesian, k-Nearest Neighbor (k-NN), Support Vector Machines (SVM) ,ANN ,Logistic Regression and Principal Component Analysis algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f87ef7827d46d14e55f921b25c7d762175e941dc"
   },
   "source": [
    "# EEG Data Recording\n",
    "EEG signals are separated into α, β, δ and θ spectral components and provide a  wide range of frequency components. EEG spectrum contains some characteristic  waveforms that fall primarily within four frequency bands as follows: δ(0.5-4 Hz),  θ(4-8 Hz), α(8-13 Hz), and β (13- 30 Hz) .\n",
    "EEG data set has acquired different age groups in this study. They are known  epileptic with uncontrolled seizures and are admitted to the neurology department of the Medical Faculty Hospital of Dicle University1. For this system LabView pro-  gramming language has been used  and the EEG data used in 400 people who re-  ceived 200 of them are epilepsy and with 200 of them are normal. Data set represents  of signals belong to several healthy and epileptic patients. The EEG signals that are  contained by PCI-MIO 16E DAQ card system that provides real time processing and  is a data bus of computer, signal processor and personal computer. Fig. 2 shows that  how to acquire EEG data from a patient [1]. EEG signals are to ensure the accuracy of  diagnosing disease that usually is taken 8-10 hours in the form of records. EEG sig-  nals are used in section and 23.6 seconds, 173 Hz sampling frequency is illustrated  with. International 10–20 electrode placement system according to the data collected,  12-bit analog-digital conversion after the samples are recorded subsequently. Data can  be passed through the filter 0.53–40 Hz band–pass, the EEG in the presence of clini-  cal interest for focusing range is provided. The EEG data used in our study were  downloaded from 24-h EEG recorded from both epileptic patients and normal sub-  jects. The following bipolar EEG channels were selected for analysis: F7-C3, F8-C4,  T5-O1 and T6-O2. In order to assess the performance of the classifier, we selected  500 EEG segments containing spike and wave complex, artifacts and background  normal EEG .\n",
    "![Imgur](https://i.imgur.com/6rQgYS9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "30e388d1b8ce7f8c9654828ef320fb39d953bab0"
   },
   "source": [
    "# Discrete Wavelet Transform\n",
    "Wavelet transform is more advantageous spectral analyze method than other  spectral analyze methods on non-stationary signals. Because the wavelet transform  method changes large low-frequency, high frequency that is narrow for the window  size. So, the entire frequency range can be achieved in the optimum time-frequency  resolution [22] Continuous and discrete wavelet transform is analyzed in the scale and  variation of parameters due to the continuous wavelet coefficients for each scale is  difficult and time consuming. For this reason, discrete wavelet transform is used more\n",
    "ften than these non-stationary signals. Wavelet scale is divided into a number of  points for x[n] process as seen in Fig. 2 that is called multi resolution decomposition.  It is important that is selected appropriate wavelet decomposition level, the number of  detection and wavelet transform analysis of signals. Because of classification accura-  cy is dependent on type of wavelet, dominant frequency components of signals are  determined according to the number of decomposition levels.\n",
    "Wavelet coefficients contain important information about EEG signal that provide  extraction of feature vector. Statistical-time frequency of EEG signals sequences are:\n",
    "\n",
    "The average of the absolute value of coefficients in each sub-band.\n",
    "The maximum absolute value of coefficients in each sub-band.\n",
    "The mean force coefficients of each sub-band.\n",
    "Standard deviation of coefficients in each sub-band.\n",
    "The average absolute value of the ratio of adjacent bands.\n",
    "Distribution of breakdown coefficients in each sub-band.\n",
    "\n",
    "1-3 sequence is signal characteristic; 4-6 sequence is that amount of frequency  change. This feature vector, of EEG signals that are used as inputs for multi-layer  neural network classification.\n",
    "![Imgur](https://i.imgur.com/Jzj3UAU.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b9ad6f280e93376b5811f0cd1f25556150660b21"
   },
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "87d159a308dde25e6f89f58501552945f4c261cf",
    "execution": {
     "iopub.execute_input": "2023-02-04T16:08:28.205389Z",
     "iopub.status.busy": "2023-02-04T16:08:28.204671Z",
     "iopub.status.idle": "2023-02-04T16:08:29.037119Z",
     "shell.execute_reply": "2023-02-04T16:08:29.035792Z",
     "shell.execute_reply.started": "2023-02-04T16:08:28.205326Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "710c7bc8e8f0ebf31b579ae609e2c8b364e4b731"
   },
   "source": [
    "# Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "ffb826c5e8da301b74c3a0161e7dcc079fec03ce",
    "execution": {
     "iopub.execute_input": "2023-02-04T16:08:49.828424Z",
     "iopub.status.busy": "2023-02-04T16:08:49.828067Z",
     "iopub.status.idle": "2023-02-04T16:08:50.233912Z",
     "shell.execute_reply": "2023-02-04T16:08:50.233179Z",
     "shell.execute_reply.started": "2023-02-04T16:08:49.828360Z"
    }
   },
   "outputs": [],
   "source": [
    "ESR = pd.read_csv('../input/Epileptic Seizure Recognition.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f747e03448e282cdb4f5a611a8aa2191acc71c80"
   },
   "source": [
    "# Read and Show Dataset\n",
    "* The original dataset from the reference consists of 5 different folders, each with 100 files, with each file representing a single subject/person. Each file is a recording of brain activity for 23.6 seconds.\n",
    "\n",
    "* The corresponding time-series is sampled into 4097 data points. Each data point is the value of the EEG recording at a different point in time. So we have total 500 individuals with each has 4097 data points for 23.5 seconds.\n",
    "\n",
    "* We divided and shuffled every 4097 data points into 23 chunks, each chunk contains 178 data points for 1 second, and each data point is the value of the EEG recording at a different point in time.\n",
    "\n",
    "* So now we have 23 x 500 = 11500 pieces of information(row), each information contains 178 data points for 1 second(column), the last column represents the label y {1,2,3,4,5}.\n",
    "\n",
    "* The response variable is y in column 179, the Explanatory variables X1, X2, ..., X178"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "98727073fd4a8acefbbe53251f25fe30986f1e2f",
    "execution": {
     "iopub.execute_input": "2023-02-04T16:08:57.655631Z",
     "iopub.status.busy": "2023-02-04T16:08:57.655316Z",
     "iopub.status.idle": "2023-02-04T16:08:57.777984Z",
     "shell.execute_reply": "2023-02-04T16:08:57.777222Z",
     "shell.execute_reply.started": "2023-02-04T16:08:57.655577Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>X11</th>\n",
       "      <th>X12</th>\n",
       "      <th>X13</th>\n",
       "      <th>X14</th>\n",
       "      <th>X15</th>\n",
       "      <th>X16</th>\n",
       "      <th>X17</th>\n",
       "      <th>X18</th>\n",
       "      <th>X19</th>\n",
       "      <th>X20</th>\n",
       "      <th>X21</th>\n",
       "      <th>X22</th>\n",
       "      <th>X23</th>\n",
       "      <th>X24</th>\n",
       "      <th>X25</th>\n",
       "      <th>X26</th>\n",
       "      <th>X27</th>\n",
       "      <th>X28</th>\n",
       "      <th>X29</th>\n",
       "      <th>X30</th>\n",
       "      <th>X31</th>\n",
       "      <th>X32</th>\n",
       "      <th>X33</th>\n",
       "      <th>X34</th>\n",
       "      <th>X35</th>\n",
       "      <th>X36</th>\n",
       "      <th>X37</th>\n",
       "      <th>X38</th>\n",
       "      <th>X39</th>\n",
       "      <th>...</th>\n",
       "      <th>X140</th>\n",
       "      <th>X141</th>\n",
       "      <th>X142</th>\n",
       "      <th>X143</th>\n",
       "      <th>X144</th>\n",
       "      <th>X145</th>\n",
       "      <th>X146</th>\n",
       "      <th>X147</th>\n",
       "      <th>X148</th>\n",
       "      <th>X149</th>\n",
       "      <th>X150</th>\n",
       "      <th>X151</th>\n",
       "      <th>X152</th>\n",
       "      <th>X153</th>\n",
       "      <th>X154</th>\n",
       "      <th>X155</th>\n",
       "      <th>X156</th>\n",
       "      <th>X157</th>\n",
       "      <th>X158</th>\n",
       "      <th>X159</th>\n",
       "      <th>X160</th>\n",
       "      <th>X161</th>\n",
       "      <th>X162</th>\n",
       "      <th>X163</th>\n",
       "      <th>X164</th>\n",
       "      <th>X165</th>\n",
       "      <th>X166</th>\n",
       "      <th>X167</th>\n",
       "      <th>X168</th>\n",
       "      <th>X169</th>\n",
       "      <th>X170</th>\n",
       "      <th>X171</th>\n",
       "      <th>X172</th>\n",
       "      <th>X173</th>\n",
       "      <th>X174</th>\n",
       "      <th>X175</th>\n",
       "      <th>X176</th>\n",
       "      <th>X177</th>\n",
       "      <th>X178</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X21.V1.791</td>\n",
       "      <td>135</td>\n",
       "      <td>190</td>\n",
       "      <td>229</td>\n",
       "      <td>223</td>\n",
       "      <td>192</td>\n",
       "      <td>125</td>\n",
       "      <td>55</td>\n",
       "      <td>-9</td>\n",
       "      <td>-33</td>\n",
       "      <td>-38</td>\n",
       "      <td>-10</td>\n",
       "      <td>35</td>\n",
       "      <td>64</td>\n",
       "      <td>113</td>\n",
       "      <td>152</td>\n",
       "      <td>164</td>\n",
       "      <td>127</td>\n",
       "      <td>50</td>\n",
       "      <td>-47</td>\n",
       "      <td>-121</td>\n",
       "      <td>-138</td>\n",
       "      <td>-125</td>\n",
       "      <td>-101</td>\n",
       "      <td>-50</td>\n",
       "      <td>11</td>\n",
       "      <td>39</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>64</td>\n",
       "      <td>46</td>\n",
       "      <td>13</td>\n",
       "      <td>-19</td>\n",
       "      <td>-61</td>\n",
       "      <td>-96</td>\n",
       "      <td>-130</td>\n",
       "      <td>-132</td>\n",
       "      <td>-116</td>\n",
       "      <td>-115</td>\n",
       "      <td>-71</td>\n",
       "      <td>...</td>\n",
       "      <td>54</td>\n",
       "      <td>90</td>\n",
       "      <td>111</td>\n",
       "      <td>107</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>18</td>\n",
       "      <td>-25</td>\n",
       "      <td>-69</td>\n",
       "      <td>-65</td>\n",
       "      <td>-44</td>\n",
       "      <td>-33</td>\n",
       "      <td>-57</td>\n",
       "      <td>-88</td>\n",
       "      <td>-114</td>\n",
       "      <td>-130</td>\n",
       "      <td>-114</td>\n",
       "      <td>-83</td>\n",
       "      <td>-53</td>\n",
       "      <td>-79</td>\n",
       "      <td>-72</td>\n",
       "      <td>-85</td>\n",
       "      <td>-109</td>\n",
       "      <td>-98</td>\n",
       "      <td>-72</td>\n",
       "      <td>-65</td>\n",
       "      <td>-63</td>\n",
       "      <td>-11</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>-17</td>\n",
       "      <td>-15</td>\n",
       "      <td>-31</td>\n",
       "      <td>-77</td>\n",
       "      <td>-103</td>\n",
       "      <td>-127</td>\n",
       "      <td>-116</td>\n",
       "      <td>-83</td>\n",
       "      <td>-51</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X15.V1.924</td>\n",
       "      <td>386</td>\n",
       "      <td>382</td>\n",
       "      <td>356</td>\n",
       "      <td>331</td>\n",
       "      <td>320</td>\n",
       "      <td>315</td>\n",
       "      <td>307</td>\n",
       "      <td>272</td>\n",
       "      <td>244</td>\n",
       "      <td>232</td>\n",
       "      <td>237</td>\n",
       "      <td>258</td>\n",
       "      <td>212</td>\n",
       "      <td>2</td>\n",
       "      <td>-267</td>\n",
       "      <td>-605</td>\n",
       "      <td>-850</td>\n",
       "      <td>-1001</td>\n",
       "      <td>-1109</td>\n",
       "      <td>-1090</td>\n",
       "      <td>-967</td>\n",
       "      <td>-746</td>\n",
       "      <td>-464</td>\n",
       "      <td>-152</td>\n",
       "      <td>118</td>\n",
       "      <td>318</td>\n",
       "      <td>427</td>\n",
       "      <td>473</td>\n",
       "      <td>485</td>\n",
       "      <td>447</td>\n",
       "      <td>397</td>\n",
       "      <td>339</td>\n",
       "      <td>312</td>\n",
       "      <td>314</td>\n",
       "      <td>326</td>\n",
       "      <td>335</td>\n",
       "      <td>332</td>\n",
       "      <td>324</td>\n",
       "      <td>310</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>146</td>\n",
       "      <td>229</td>\n",
       "      <td>269</td>\n",
       "      <td>297</td>\n",
       "      <td>307</td>\n",
       "      <td>303</td>\n",
       "      <td>305</td>\n",
       "      <td>306</td>\n",
       "      <td>307</td>\n",
       "      <td>280</td>\n",
       "      <td>231</td>\n",
       "      <td>159</td>\n",
       "      <td>85</td>\n",
       "      <td>51</td>\n",
       "      <td>43</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>69</td>\n",
       "      <td>89</td>\n",
       "      <td>123</td>\n",
       "      <td>136</td>\n",
       "      <td>127</td>\n",
       "      <td>102</td>\n",
       "      <td>95</td>\n",
       "      <td>105</td>\n",
       "      <td>131</td>\n",
       "      <td>163</td>\n",
       "      <td>168</td>\n",
       "      <td>164</td>\n",
       "      <td>150</td>\n",
       "      <td>146</td>\n",
       "      <td>152</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>154</td>\n",
       "      <td>143</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X8.V1.1</td>\n",
       "      <td>-32</td>\n",
       "      <td>-39</td>\n",
       "      <td>-47</td>\n",
       "      <td>-37</td>\n",
       "      <td>-32</td>\n",
       "      <td>-36</td>\n",
       "      <td>-57</td>\n",
       "      <td>-73</td>\n",
       "      <td>-85</td>\n",
       "      <td>-94</td>\n",
       "      <td>-99</td>\n",
       "      <td>-94</td>\n",
       "      <td>-96</td>\n",
       "      <td>-104</td>\n",
       "      <td>-103</td>\n",
       "      <td>-92</td>\n",
       "      <td>-75</td>\n",
       "      <td>-69</td>\n",
       "      <td>-69</td>\n",
       "      <td>-53</td>\n",
       "      <td>-37</td>\n",
       "      <td>-14</td>\n",
       "      <td>-10</td>\n",
       "      <td>-39</td>\n",
       "      <td>-78</td>\n",
       "      <td>-102</td>\n",
       "      <td>-98</td>\n",
       "      <td>-80</td>\n",
       "      <td>-54</td>\n",
       "      <td>-40</td>\n",
       "      <td>-35</td>\n",
       "      <td>-39</td>\n",
       "      <td>-32</td>\n",
       "      <td>-13</td>\n",
       "      <td>7</td>\n",
       "      <td>34</td>\n",
       "      <td>41</td>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>-82</td>\n",
       "      <td>-107</td>\n",
       "      <td>-126</td>\n",
       "      <td>-124</td>\n",
       "      <td>-108</td>\n",
       "      <td>-84</td>\n",
       "      <td>-68</td>\n",
       "      <td>-61</td>\n",
       "      <td>-56</td>\n",
       "      <td>-63</td>\n",
       "      <td>-62</td>\n",
       "      <td>-33</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>45</td>\n",
       "      <td>37</td>\n",
       "      <td>48</td>\n",
       "      <td>62</td>\n",
       "      <td>80</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>-11</td>\n",
       "      <td>-39</td>\n",
       "      <td>-44</td>\n",
       "      <td>-42</td>\n",
       "      <td>-45</td>\n",
       "      <td>-48</td>\n",
       "      <td>-42</td>\n",
       "      <td>-6</td>\n",
       "      <td>29</td>\n",
       "      <td>57</td>\n",
       "      <td>64</td>\n",
       "      <td>48</td>\n",
       "      <td>19</td>\n",
       "      <td>-12</td>\n",
       "      <td>-30</td>\n",
       "      <td>-35</td>\n",
       "      <td>-35</td>\n",
       "      <td>-36</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X16.V1.60</td>\n",
       "      <td>-105</td>\n",
       "      <td>-101</td>\n",
       "      <td>-96</td>\n",
       "      <td>-92</td>\n",
       "      <td>-89</td>\n",
       "      <td>-95</td>\n",
       "      <td>-102</td>\n",
       "      <td>-100</td>\n",
       "      <td>-87</td>\n",
       "      <td>-79</td>\n",
       "      <td>-72</td>\n",
       "      <td>-68</td>\n",
       "      <td>-74</td>\n",
       "      <td>-80</td>\n",
       "      <td>-83</td>\n",
       "      <td>-73</td>\n",
       "      <td>-68</td>\n",
       "      <td>-61</td>\n",
       "      <td>-58</td>\n",
       "      <td>-59</td>\n",
       "      <td>-64</td>\n",
       "      <td>-79</td>\n",
       "      <td>-84</td>\n",
       "      <td>-97</td>\n",
       "      <td>-94</td>\n",
       "      <td>-84</td>\n",
       "      <td>-77</td>\n",
       "      <td>-75</td>\n",
       "      <td>-72</td>\n",
       "      <td>-68</td>\n",
       "      <td>-76</td>\n",
       "      <td>-76</td>\n",
       "      <td>-72</td>\n",
       "      <td>-67</td>\n",
       "      <td>-69</td>\n",
       "      <td>-69</td>\n",
       "      <td>-69</td>\n",
       "      <td>-67</td>\n",
       "      <td>-68</td>\n",
       "      <td>...</td>\n",
       "      <td>-69</td>\n",
       "      <td>-66</td>\n",
       "      <td>-74</td>\n",
       "      <td>-69</td>\n",
       "      <td>-61</td>\n",
       "      <td>-51</td>\n",
       "      <td>-45</td>\n",
       "      <td>-45</td>\n",
       "      <td>-49</td>\n",
       "      <td>-58</td>\n",
       "      <td>-64</td>\n",
       "      <td>-78</td>\n",
       "      <td>-80</td>\n",
       "      <td>-90</td>\n",
       "      <td>-87</td>\n",
       "      <td>-83</td>\n",
       "      <td>-78</td>\n",
       "      <td>-64</td>\n",
       "      <td>-38</td>\n",
       "      <td>-22</td>\n",
       "      <td>-29</td>\n",
       "      <td>-42</td>\n",
       "      <td>-51</td>\n",
       "      <td>-68</td>\n",
       "      <td>-71</td>\n",
       "      <td>-69</td>\n",
       "      <td>-69</td>\n",
       "      <td>-74</td>\n",
       "      <td>-74</td>\n",
       "      <td>-80</td>\n",
       "      <td>-82</td>\n",
       "      <td>-81</td>\n",
       "      <td>-80</td>\n",
       "      <td>-77</td>\n",
       "      <td>-85</td>\n",
       "      <td>-77</td>\n",
       "      <td>-72</td>\n",
       "      <td>-69</td>\n",
       "      <td>-65</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X20.V1.54</td>\n",
       "      <td>-9</td>\n",
       "      <td>-65</td>\n",
       "      <td>-98</td>\n",
       "      <td>-102</td>\n",
       "      <td>-78</td>\n",
       "      <td>-48</td>\n",
       "      <td>-16</td>\n",
       "      <td>0</td>\n",
       "      <td>-21</td>\n",
       "      <td>-59</td>\n",
       "      <td>-90</td>\n",
       "      <td>-103</td>\n",
       "      <td>-84</td>\n",
       "      <td>-43</td>\n",
       "      <td>-9</td>\n",
       "      <td>3</td>\n",
       "      <td>-21</td>\n",
       "      <td>-60</td>\n",
       "      <td>-96</td>\n",
       "      <td>-103</td>\n",
       "      <td>-75</td>\n",
       "      <td>-29</td>\n",
       "      <td>14</td>\n",
       "      <td>55</td>\n",
       "      <td>78</td>\n",
       "      <td>73</td>\n",
       "      <td>28</td>\n",
       "      <td>-13</td>\n",
       "      <td>-43</td>\n",
       "      <td>-68</td>\n",
       "      <td>-78</td>\n",
       "      <td>-75</td>\n",
       "      <td>-55</td>\n",
       "      <td>-41</td>\n",
       "      <td>-19</td>\n",
       "      <td>-20</td>\n",
       "      <td>-29</td>\n",
       "      <td>-36</td>\n",
       "      <td>-20</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>-4</td>\n",
       "      <td>-13</td>\n",
       "      <td>-8</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>29</td>\n",
       "      <td>57</td>\n",
       "      <td>63</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>-13</td>\n",
       "      <td>-23</td>\n",
       "      <td>-9</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-12</td>\n",
       "      <td>-32</td>\n",
       "      <td>-41</td>\n",
       "      <td>-65</td>\n",
       "      <td>-83</td>\n",
       "      <td>-89</td>\n",
       "      <td>-73</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed   X1   X2   X3   X4   X5 ...  X174  X175  X176  X177  X178  y\n",
       "0  X21.V1.791  135  190  229  223  192 ...  -103  -127  -116   -83   -51  4\n",
       "1  X15.V1.924  386  382  356  331  320 ...   157   156   154   143   129  1\n",
       "2     X8.V1.1  -32  -39  -47  -37  -32 ...   -12   -30   -35   -35   -36  5\n",
       "3   X16.V1.60 -105 -101  -96  -92  -89 ...   -85   -77   -72   -69   -65  5\n",
       "4   X20.V1.54   -9  -65  -98 -102  -78 ...   -41   -65   -83   -89   -73  5\n",
       "\n",
       "[5 rows x 180 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ESR.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "17c90c1ff8add7ace30bd8d2cfb1fa5cb48c0e48",
    "execution": {
     "iopub.execute_input": "2023-02-04T16:09:26.396473Z",
     "iopub.status.busy": "2023-02-04T16:09:26.395993Z",
     "iopub.status.idle": "2023-02-04T16:09:26.695364Z",
     "shell.execute_reply": "2023-02-04T16:09:26.694147Z",
     "shell.execute_reply.started": "2023-02-04T16:09:26.396249Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of trials for the non-seizure class is: 9200\n",
      "The number of trials for the seizure class is: 2300\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = ESR.columns\n",
    "tgt = ESR.y\n",
    "tgt[tgt>1]=0\n",
    "ax = sn.countplot(tgt,label=\"Count\")\n",
    "non_seizure, seizure = tgt.value_counts()\n",
    "print('The number of trials for the non-seizure class is:', non_seizure)\n",
    "print('The number of trials for the seizure class is:', seizure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3b8358047321392e0f1a2fb20ca53c6668d8cdf3"
   },
   "source": [
    "As we can see, there are 178 EEG features and 5 possible classes. The main goal of the dataset it's to be able to correctly identify epileptic seizures from EEG data, so a binary classification between classes of label 1 and the rest (2,3,4,5). In order to train our model, let's define our independent variables (X) and our dependent variable (y)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "85c42387f7cbe1d864e6ecd78110d36543b49c94"
   },
   "source": [
    "#  &#128223; Data Pre-processing\n",
    "\n",
    "## What is Data Pre-pocessing?\n",
    "![Imgur](https://i.imgur.com/HyPUqwF.png)\n",
    "Data preprocessing is a data mining technique that involves transforming raw data into an understandable format. Real-world data is often incomplete, inconsistent, and/or lacking in certain behaviors or trends, and is likely to contain many errors. Data preprocessing is a proven method of resolving such issues. Data preprocessing prepares raw data for further processing.\n",
    "![Imgur](https://i.imgur.com/VuYZfho.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "552d8f6aa05052620464a652d2a381c266a2fd98"
   },
   "source": [
    "## &#128223; 1. Checking Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "aad4b40423e626080316e9baf284b7ee75b64d08",
    "execution": {
     "iopub.execute_input": "2023-02-04T16:10:06.870661Z",
     "iopub.status.busy": "2023-02-04T16:10:06.870345Z",
     "iopub.status.idle": "2023-02-04T16:10:06.908863Z",
     "shell.execute_reply": "2023-02-04T16:10:06.907736Z",
     "shell.execute_reply.started": "2023-02-04T16:10:06.870605Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed    0\n",
       "X1         0\n",
       "X2         0\n",
       "X3         0\n",
       "X4         0\n",
       "X5         0\n",
       "X6         0\n",
       "X7         0\n",
       "X8         0\n",
       "X9         0\n",
       "X10        0\n",
       "X11        0\n",
       "X12        0\n",
       "X13        0\n",
       "X14        0\n",
       "X15        0\n",
       "X16        0\n",
       "X17        0\n",
       "X18        0\n",
       "X19        0\n",
       "X20        0\n",
       "X21        0\n",
       "X22        0\n",
       "X23        0\n",
       "X24        0\n",
       "X25        0\n",
       "X26        0\n",
       "X27        0\n",
       "X28        0\n",
       "X29        0\n",
       "          ..\n",
       "X150       0\n",
       "X151       0\n",
       "X152       0\n",
       "X153       0\n",
       "X154       0\n",
       "X155       0\n",
       "X156       0\n",
       "X157       0\n",
       "X158       0\n",
       "X159       0\n",
       "X160       0\n",
       "X161       0\n",
       "X162       0\n",
       "X163       0\n",
       "X164       0\n",
       "X165       0\n",
       "X166       0\n",
       "X167       0\n",
       "X168       0\n",
       "X169       0\n",
       "X170       0\n",
       "X171       0\n",
       "X172       0\n",
       "X173       0\n",
       "X174       0\n",
       "X175       0\n",
       "X176       0\n",
       "X177       0\n",
       "X178       0\n",
       "y          0\n",
       "Length: 180, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ESR.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dc7b27a8bd5b7cea21b2dcd3a3c29676e18c1bb4"
   },
   "source": [
    "###  &#128210; Note:\n",
    "Thats great here is no missing value. So we can work very smoothly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ab3a886cede2b110c7a6f5a28f42a15b478559e0"
   },
   "source": [
    "# &#128203; Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cdaf9a18dd4802a74fda29c78b594fdea389e2b1"
   },
   "source": [
    "## &#128505; What is Exploratory data analysis?\n",
    "![Imgur](https://i.imgur.com/HyPUqwF.png)\n",
    "In statistics, exploratory data analysis (EDA) is an approach to analyzing data sets to summarize their main characteristics, often with visual methods. A statistical model can be used or not, but primarily EDA is for seeing what the data can tell us beyond the formal modeling or hypothesis testing task.\n",
    "\n",
    "You can say that EDA is statisticians way of story telling where you explore data, find patterns and tells insights. Often you have some questions in hand you try to validate those questions by performing EDA. <b>I have one article on [EDA](https://hackernoon.com/overview-of-exploratory-data-analysis-with-python-6213e105b00b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "e88bcff9f978e728a07d29bd99eee000ec0e3bcc",
    "execution": {
     "iopub.execute_input": "2023-02-04T16:10:26.015589Z",
     "iopub.status.busy": "2023-02-04T16:10:26.015232Z",
     "iopub.status.idle": "2023-02-04T16:10:26.029739Z",
     "shell.execute_reply": "2023-02-04T16:10:26.028925Z",
     "shell.execute_reply.started": "2023-02-04T16:10:26.015530Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11500 entries, 0 to 11499\n",
      "Columns: 180 entries, Unnamed to y\n",
      "dtypes: int64(179), object(1)\n",
      "memory usage: 15.8+ MB\n"
     ]
    }
   ],
   "source": [
    "ESR.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "c59e74a086f2f41b14f793b599f0938cdab43704",
    "execution": {
     "iopub.execute_input": "2023-02-04T16:10:39.311060Z",
     "iopub.status.busy": "2023-02-04T16:10:39.310656Z",
     "iopub.status.idle": "2023-02-04T16:10:39.905784Z",
     "shell.execute_reply": "2023-02-04T16:10:39.904746Z",
     "shell.execute_reply.started": "2023-02-04T16:10:39.310985Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>X11</th>\n",
       "      <th>X12</th>\n",
       "      <th>X13</th>\n",
       "      <th>X14</th>\n",
       "      <th>X15</th>\n",
       "      <th>X16</th>\n",
       "      <th>X17</th>\n",
       "      <th>X18</th>\n",
       "      <th>X19</th>\n",
       "      <th>X20</th>\n",
       "      <th>X21</th>\n",
       "      <th>X22</th>\n",
       "      <th>X23</th>\n",
       "      <th>X24</th>\n",
       "      <th>X25</th>\n",
       "      <th>X26</th>\n",
       "      <th>X27</th>\n",
       "      <th>X28</th>\n",
       "      <th>X29</th>\n",
       "      <th>X30</th>\n",
       "      <th>X31</th>\n",
       "      <th>X32</th>\n",
       "      <th>X33</th>\n",
       "      <th>X34</th>\n",
       "      <th>X35</th>\n",
       "      <th>X36</th>\n",
       "      <th>X37</th>\n",
       "      <th>X38</th>\n",
       "      <th>X39</th>\n",
       "      <th>X40</th>\n",
       "      <th>...</th>\n",
       "      <th>X140</th>\n",
       "      <th>X141</th>\n",
       "      <th>X142</th>\n",
       "      <th>X143</th>\n",
       "      <th>X144</th>\n",
       "      <th>X145</th>\n",
       "      <th>X146</th>\n",
       "      <th>X147</th>\n",
       "      <th>X148</th>\n",
       "      <th>X149</th>\n",
       "      <th>X150</th>\n",
       "      <th>X151</th>\n",
       "      <th>X152</th>\n",
       "      <th>X153</th>\n",
       "      <th>X154</th>\n",
       "      <th>X155</th>\n",
       "      <th>X156</th>\n",
       "      <th>X157</th>\n",
       "      <th>X158</th>\n",
       "      <th>X159</th>\n",
       "      <th>X160</th>\n",
       "      <th>X161</th>\n",
       "      <th>X162</th>\n",
       "      <th>X163</th>\n",
       "      <th>X164</th>\n",
       "      <th>X165</th>\n",
       "      <th>X166</th>\n",
       "      <th>X167</th>\n",
       "      <th>X168</th>\n",
       "      <th>X169</th>\n",
       "      <th>X170</th>\n",
       "      <th>X171</th>\n",
       "      <th>X172</th>\n",
       "      <th>X173</th>\n",
       "      <th>X174</th>\n",
       "      <th>X175</th>\n",
       "      <th>X176</th>\n",
       "      <th>X177</th>\n",
       "      <th>X178</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.00000</td>\n",
       "      <td>11500.00000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.00000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-11.581391</td>\n",
       "      <td>-10.911565</td>\n",
       "      <td>-10.187130</td>\n",
       "      <td>-9.143043</td>\n",
       "      <td>-8.009739</td>\n",
       "      <td>-7.003478</td>\n",
       "      <td>-6.502087</td>\n",
       "      <td>-6.68713</td>\n",
       "      <td>-6.55800</td>\n",
       "      <td>-6.168435</td>\n",
       "      <td>-5.827478</td>\n",
       "      <td>-6.042174</td>\n",
       "      <td>-6.687304</td>\n",
       "      <td>-7.088870</td>\n",
       "      <td>-7.211217</td>\n",
       "      <td>-7.088261</td>\n",
       "      <td>-6.806696</td>\n",
       "      <td>-6.744696</td>\n",
       "      <td>-6.484783</td>\n",
       "      <td>-6.448435</td>\n",
       "      <td>-6.355391</td>\n",
       "      <td>-6.543130</td>\n",
       "      <td>-6.884348</td>\n",
       "      <td>-6.883217</td>\n",
       "      <td>-6.118870</td>\n",
       "      <td>-5.15913</td>\n",
       "      <td>-4.785652</td>\n",
       "      <td>-4.874783</td>\n",
       "      <td>-5.393565</td>\n",
       "      <td>-5.935478</td>\n",
       "      <td>-6.349913</td>\n",
       "      <td>-6.212522</td>\n",
       "      <td>-5.859826</td>\n",
       "      <td>-5.299826</td>\n",
       "      <td>-4.955652</td>\n",
       "      <td>-5.278087</td>\n",
       "      <td>-6.162261</td>\n",
       "      <td>-7.316609</td>\n",
       "      <td>-7.998522</td>\n",
       "      <td>-7.818870</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.997304</td>\n",
       "      <td>-7.339391</td>\n",
       "      <td>-7.911565</td>\n",
       "      <td>-8.177304</td>\n",
       "      <td>-8.608870</td>\n",
       "      <td>-8.578087</td>\n",
       "      <td>-8.240000</td>\n",
       "      <td>-7.691391</td>\n",
       "      <td>-7.356522</td>\n",
       "      <td>-7.228783</td>\n",
       "      <td>-6.980870</td>\n",
       "      <td>-6.756783</td>\n",
       "      <td>-6.355304</td>\n",
       "      <td>-6.423826</td>\n",
       "      <td>-6.465217</td>\n",
       "      <td>-6.316435</td>\n",
       "      <td>-5.808000</td>\n",
       "      <td>-5.255913</td>\n",
       "      <td>-4.682087</td>\n",
       "      <td>-4.638609</td>\n",
       "      <td>-4.770261</td>\n",
       "      <td>-5.650870</td>\n",
       "      <td>-7.170348</td>\n",
       "      <td>-8.759826</td>\n",
       "      <td>-9.784783</td>\n",
       "      <td>-10.096261</td>\n",
       "      <td>-9.842957</td>\n",
       "      <td>-9.701739</td>\n",
       "      <td>-9.351391</td>\n",
       "      <td>-9.498870</td>\n",
       "      <td>-10.145739</td>\n",
       "      <td>-11.630348</td>\n",
       "      <td>-12.943478</td>\n",
       "      <td>-13.668870</td>\n",
       "      <td>-13.363304</td>\n",
       "      <td>-13.045043</td>\n",
       "      <td>-12.705130</td>\n",
       "      <td>-12.426000</td>\n",
       "      <td>-12.195652</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>165.626284</td>\n",
       "      <td>166.059609</td>\n",
       "      <td>163.524317</td>\n",
       "      <td>161.269041</td>\n",
       "      <td>160.998007</td>\n",
       "      <td>161.328725</td>\n",
       "      <td>161.467837</td>\n",
       "      <td>162.11912</td>\n",
       "      <td>162.03336</td>\n",
       "      <td>160.436352</td>\n",
       "      <td>160.471017</td>\n",
       "      <td>161.181118</td>\n",
       "      <td>165.071121</td>\n",
       "      <td>169.198359</td>\n",
       "      <td>170.641967</td>\n",
       "      <td>168.930355</td>\n",
       "      <td>164.646296</td>\n",
       "      <td>162.062661</td>\n",
       "      <td>162.571333</td>\n",
       "      <td>162.339911</td>\n",
       "      <td>162.823325</td>\n",
       "      <td>163.909723</td>\n",
       "      <td>165.844176</td>\n",
       "      <td>166.009100</td>\n",
       "      <td>164.715153</td>\n",
       "      <td>162.77423</td>\n",
       "      <td>162.902294</td>\n",
       "      <td>164.799831</td>\n",
       "      <td>165.391697</td>\n",
       "      <td>164.291120</td>\n",
       "      <td>163.165167</td>\n",
       "      <td>163.408052</td>\n",
       "      <td>163.561408</td>\n",
       "      <td>162.548119</td>\n",
       "      <td>160.813772</td>\n",
       "      <td>160.441049</td>\n",
       "      <td>162.881958</td>\n",
       "      <td>166.235164</td>\n",
       "      <td>166.314965</td>\n",
       "      <td>164.513017</td>\n",
       "      <td>...</td>\n",
       "      <td>168.567495</td>\n",
       "      <td>168.662705</td>\n",
       "      <td>167.643458</td>\n",
       "      <td>167.414439</td>\n",
       "      <td>167.922773</td>\n",
       "      <td>168.274009</td>\n",
       "      <td>167.808218</td>\n",
       "      <td>166.739558</td>\n",
       "      <td>165.678558</td>\n",
       "      <td>167.130911</td>\n",
       "      <td>168.156296</td>\n",
       "      <td>167.459868</td>\n",
       "      <td>165.061414</td>\n",
       "      <td>164.248830</td>\n",
       "      <td>166.226332</td>\n",
       "      <td>168.143625</td>\n",
       "      <td>167.067064</td>\n",
       "      <td>166.446540</td>\n",
       "      <td>167.554020</td>\n",
       "      <td>169.418457</td>\n",
       "      <td>170.639171</td>\n",
       "      <td>170.817824</td>\n",
       "      <td>168.145372</td>\n",
       "      <td>166.817974</td>\n",
       "      <td>166.999981</td>\n",
       "      <td>167.756860</td>\n",
       "      <td>166.988820</td>\n",
       "      <td>167.062497</td>\n",
       "      <td>166.606345</td>\n",
       "      <td>165.235574</td>\n",
       "      <td>164.652883</td>\n",
       "      <td>166.149790</td>\n",
       "      <td>168.554058</td>\n",
       "      <td>168.556486</td>\n",
       "      <td>167.257290</td>\n",
       "      <td>164.241019</td>\n",
       "      <td>162.895832</td>\n",
       "      <td>162.886311</td>\n",
       "      <td>164.852015</td>\n",
       "      <td>0.400017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1839.000000</td>\n",
       "      <td>-1838.000000</td>\n",
       "      <td>-1835.000000</td>\n",
       "      <td>-1845.000000</td>\n",
       "      <td>-1791.000000</td>\n",
       "      <td>-1757.000000</td>\n",
       "      <td>-1832.000000</td>\n",
       "      <td>-1778.00000</td>\n",
       "      <td>-1840.00000</td>\n",
       "      <td>-1867.000000</td>\n",
       "      <td>-1765.000000</td>\n",
       "      <td>-1803.000000</td>\n",
       "      <td>-1833.000000</td>\n",
       "      <td>-1867.000000</td>\n",
       "      <td>-1870.000000</td>\n",
       "      <td>-1839.000000</td>\n",
       "      <td>-1867.000000</td>\n",
       "      <td>-1856.000000</td>\n",
       "      <td>-1844.000000</td>\n",
       "      <td>-1717.000000</td>\n",
       "      <td>-1764.000000</td>\n",
       "      <td>-1856.000000</td>\n",
       "      <td>-1844.000000</td>\n",
       "      <td>-1866.000000</td>\n",
       "      <td>-1863.000000</td>\n",
       "      <td>-1866.00000</td>\n",
       "      <td>-1781.000000</td>\n",
       "      <td>-1860.000000</td>\n",
       "      <td>-1818.000000</td>\n",
       "      <td>-1867.000000</td>\n",
       "      <td>-1743.000000</td>\n",
       "      <td>-1517.000000</td>\n",
       "      <td>-1552.000000</td>\n",
       "      <td>-1720.000000</td>\n",
       "      <td>-1864.000000</td>\n",
       "      <td>-1814.000000</td>\n",
       "      <td>-1829.000000</td>\n",
       "      <td>-1851.000000</td>\n",
       "      <td>-1840.000000</td>\n",
       "      <td>-1673.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1867.000000</td>\n",
       "      <td>-1826.000000</td>\n",
       "      <td>-1866.000000</td>\n",
       "      <td>-1854.000000</td>\n",
       "      <td>-1789.000000</td>\n",
       "      <td>-1872.000000</td>\n",
       "      <td>-1866.000000</td>\n",
       "      <td>-1675.000000</td>\n",
       "      <td>-1778.000000</td>\n",
       "      <td>-1733.000000</td>\n",
       "      <td>-1862.000000</td>\n",
       "      <td>-1861.000000</td>\n",
       "      <td>-1857.000000</td>\n",
       "      <td>-1839.000000</td>\n",
       "      <td>-1860.000000</td>\n",
       "      <td>-1843.000000</td>\n",
       "      <td>-1863.000000</td>\n",
       "      <td>-1861.000000</td>\n",
       "      <td>-1845.000000</td>\n",
       "      <td>-1820.000000</td>\n",
       "      <td>-1864.000000</td>\n",
       "      <td>-1868.000000</td>\n",
       "      <td>-1855.000000</td>\n",
       "      <td>-1852.000000</td>\n",
       "      <td>-1870.000000</td>\n",
       "      <td>-1847.000000</td>\n",
       "      <td>-1578.000000</td>\n",
       "      <td>-1838.000000</td>\n",
       "      <td>-1763.000000</td>\n",
       "      <td>-1860.000000</td>\n",
       "      <td>-1867.000000</td>\n",
       "      <td>-1865.000000</td>\n",
       "      <td>-1642.000000</td>\n",
       "      <td>-1723.000000</td>\n",
       "      <td>-1866.000000</td>\n",
       "      <td>-1863.000000</td>\n",
       "      <td>-1781.000000</td>\n",
       "      <td>-1727.000000</td>\n",
       "      <td>-1829.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-54.000000</td>\n",
       "      <td>-55.000000</td>\n",
       "      <td>-54.000000</td>\n",
       "      <td>-54.000000</td>\n",
       "      <td>-54.000000</td>\n",
       "      <td>-54.000000</td>\n",
       "      <td>-54.000000</td>\n",
       "      <td>-55.00000</td>\n",
       "      <td>-55.00000</td>\n",
       "      <td>-54.000000</td>\n",
       "      <td>-54.000000</td>\n",
       "      <td>-54.000000</td>\n",
       "      <td>-54.000000</td>\n",
       "      <td>-54.000000</td>\n",
       "      <td>-53.000000</td>\n",
       "      <td>-53.000000</td>\n",
       "      <td>-53.000000</td>\n",
       "      <td>-52.000000</td>\n",
       "      <td>-53.000000</td>\n",
       "      <td>-53.000000</td>\n",
       "      <td>-53.000000</td>\n",
       "      <td>-53.000000</td>\n",
       "      <td>-53.000000</td>\n",
       "      <td>-52.000000</td>\n",
       "      <td>-52.000000</td>\n",
       "      <td>-52.00000</td>\n",
       "      <td>-51.000000</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>-51.000000</td>\n",
       "      <td>-52.000000</td>\n",
       "      <td>-52.000000</td>\n",
       "      <td>-51.000000</td>\n",
       "      <td>-51.000000</td>\n",
       "      <td>-51.000000</td>\n",
       "      <td>-51.000000</td>\n",
       "      <td>-51.000000</td>\n",
       "      <td>-52.000000</td>\n",
       "      <td>-52.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-54.000000</td>\n",
       "      <td>-55.000000</td>\n",
       "      <td>-55.000000</td>\n",
       "      <td>-56.000000</td>\n",
       "      <td>-56.000000</td>\n",
       "      <td>-56.000000</td>\n",
       "      <td>-55.000000</td>\n",
       "      <td>-57.000000</td>\n",
       "      <td>-55.000000</td>\n",
       "      <td>-55.000000</td>\n",
       "      <td>-54.000000</td>\n",
       "      <td>-54.000000</td>\n",
       "      <td>-53.000000</td>\n",
       "      <td>-53.000000</td>\n",
       "      <td>-53.000000</td>\n",
       "      <td>-52.000000</td>\n",
       "      <td>-52.250000</td>\n",
       "      <td>-52.000000</td>\n",
       "      <td>-52.000000</td>\n",
       "      <td>-53.000000</td>\n",
       "      <td>-52.000000</td>\n",
       "      <td>-52.000000</td>\n",
       "      <td>-52.000000</td>\n",
       "      <td>-53.000000</td>\n",
       "      <td>-54.000000</td>\n",
       "      <td>-54.000000</td>\n",
       "      <td>-55.000000</td>\n",
       "      <td>-55.000000</td>\n",
       "      <td>-55.000000</td>\n",
       "      <td>-55.000000</td>\n",
       "      <td>-55.000000</td>\n",
       "      <td>-56.000000</td>\n",
       "      <td>-56.000000</td>\n",
       "      <td>-56.000000</td>\n",
       "      <td>-55.000000</td>\n",
       "      <td>-56.000000</td>\n",
       "      <td>-55.000000</td>\n",
       "      <td>-55.000000</td>\n",
       "      <td>-55.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-8.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>-8.00000</td>\n",
       "      <td>-7.00000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>-6.00000</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>36.00000</td>\n",
       "      <td>36.00000</td>\n",
       "      <td>35.250000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>38.00000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>38.250000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>35.250000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1726.000000</td>\n",
       "      <td>1713.000000</td>\n",
       "      <td>1697.000000</td>\n",
       "      <td>1612.000000</td>\n",
       "      <td>1518.000000</td>\n",
       "      <td>1816.000000</td>\n",
       "      <td>2047.000000</td>\n",
       "      <td>2047.00000</td>\n",
       "      <td>2047.00000</td>\n",
       "      <td>2047.000000</td>\n",
       "      <td>2047.000000</td>\n",
       "      <td>2047.000000</td>\n",
       "      <td>2047.000000</td>\n",
       "      <td>1829.000000</td>\n",
       "      <td>1631.000000</td>\n",
       "      <td>1532.000000</td>\n",
       "      <td>1441.000000</td>\n",
       "      <td>1352.000000</td>\n",
       "      <td>1504.000000</td>\n",
       "      <td>1821.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>2047.000000</td>\n",
       "      <td>2040.000000</td>\n",
       "      <td>1879.000000</td>\n",
       "      <td>1666.000000</td>\n",
       "      <td>1435.00000</td>\n",
       "      <td>1340.000000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1452.000000</td>\n",
       "      <td>1551.000000</td>\n",
       "      <td>1446.000000</td>\n",
       "      <td>1381.000000</td>\n",
       "      <td>1259.000000</td>\n",
       "      <td>1213.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "      <td>1220.000000</td>\n",
       "      <td>1304.000000</td>\n",
       "      <td>1344.000000</td>\n",
       "      <td>1298.000000</td>\n",
       "      <td>1518.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2047.000000</td>\n",
       "      <td>2047.000000</td>\n",
       "      <td>2047.000000</td>\n",
       "      <td>2045.000000</td>\n",
       "      <td>2047.000000</td>\n",
       "      <td>2047.000000</td>\n",
       "      <td>2047.000000</td>\n",
       "      <td>2047.000000</td>\n",
       "      <td>1934.000000</td>\n",
       "      <td>1644.000000</td>\n",
       "      <td>1524.000000</td>\n",
       "      <td>1565.000000</td>\n",
       "      <td>1682.000000</td>\n",
       "      <td>1977.000000</td>\n",
       "      <td>2047.000000</td>\n",
       "      <td>2047.000000</td>\n",
       "      <td>1902.000000</td>\n",
       "      <td>1681.000000</td>\n",
       "      <td>1502.000000</td>\n",
       "      <td>1314.000000</td>\n",
       "      <td>1431.000000</td>\n",
       "      <td>1543.000000</td>\n",
       "      <td>1556.000000</td>\n",
       "      <td>1597.000000</td>\n",
       "      <td>1629.000000</td>\n",
       "      <td>1726.000000</td>\n",
       "      <td>2047.000000</td>\n",
       "      <td>2047.000000</td>\n",
       "      <td>2047.000000</td>\n",
       "      <td>2047.000000</td>\n",
       "      <td>1777.000000</td>\n",
       "      <td>1472.000000</td>\n",
       "      <td>1319.000000</td>\n",
       "      <td>1436.000000</td>\n",
       "      <td>1733.000000</td>\n",
       "      <td>1958.000000</td>\n",
       "      <td>2047.000000</td>\n",
       "      <td>2047.000000</td>\n",
       "      <td>1915.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 X1            X2      ...               X178             y\n",
       "count  11500.000000  11500.000000      ...       11500.000000  11500.000000\n",
       "mean     -11.581391    -10.911565      ...         -12.195652      0.200000\n",
       "std      165.626284    166.059609      ...         164.852015      0.400017\n",
       "min    -1839.000000  -1838.000000      ...       -1829.000000      0.000000\n",
       "25%      -54.000000    -55.000000      ...         -55.000000      0.000000\n",
       "50%       -8.000000     -8.000000      ...          -9.000000      0.000000\n",
       "75%       34.000000     35.000000      ...          34.000000      0.000000\n",
       "max     1726.000000   1713.000000      ...        1915.000000      1.000000\n",
       "\n",
       "[8 rows x 179 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ESR.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "38ab208871375f43e6afced6a807f23a85468a68",
    "execution": {
     "iopub.execute_input": "2023-02-04T16:10:49.746534Z",
     "iopub.status.busy": "2023-02-04T16:10:49.746185Z",
     "iopub.status.idle": "2023-02-04T16:10:49.765183Z",
     "shell.execute_reply": "2023-02-04T16:10:49.764214Z",
     "shell.execute_reply.started": "2023-02-04T16:10:49.746475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11500, 178)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = ESR.iloc[:,1:179].values\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "1c4c72aceecdc35866aee2ec777a435abaf46fc3",
    "execution": {
     "iopub.execute_input": "2023-02-04T16:11:20.937057Z",
     "iopub.status.busy": "2023-02-04T16:11:20.936736Z",
     "iopub.status.idle": "2023-02-04T16:11:21.824779Z",
     "shell.execute_reply": "2023-02-04T16:11:21.823734Z",
     "shell.execute_reply.started": "2023-02-04T16:11:20.936999Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'Samples')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(511)\n",
    "plt.plot(X[1,:])\n",
    "plt.title('Classes')\n",
    "plt.ylabel('uV')\n",
    "plt.subplot(512)\n",
    "plt.plot(X[7,:])\n",
    "plt.subplot(513)\n",
    "plt.plot(X[12,:])\n",
    "plt.subplot(514)\n",
    "plt.plot(X[0,:])\n",
    "plt.subplot(515)\n",
    "plt.plot(X[2,:])\n",
    "plt.xlabel('Samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "32875b29c90672f90bdba34fcb94656dfce9fb70",
    "execution": {
     "iopub.execute_input": "2023-02-04T16:14:52.800876Z",
     "iopub.status.busy": "2023-02-04T16:14:52.800558Z",
     "iopub.status.idle": "2023-02-04T16:14:52.807457Z",
     "shell.execute_reply": "2023-02-04T16:14:52.806187Z",
     "shell.execute_reply.started": "2023-02-04T16:14:52.800818Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = ESR.iloc[:,179].values\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "182336e56e686533317d167bda1b5de60e3a3d14"
   },
   "source": [
    "To make this a binary problem, let's turn the non-seizure classes 0 while maintaining the seizure as 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "67cdd58fc5bdc0fea9fff3a6c3eb030d17bb5fef",
    "execution": {
     "iopub.execute_input": "2023-02-04T16:15:09.285873Z",
     "iopub.status.busy": "2023-02-04T16:15:09.285566Z",
     "iopub.status.idle": "2023-02-04T16:15:09.291567Z",
     "shell.execute_reply": "2023-02-04T16:15:09.290732Z",
     "shell.execute_reply.started": "2023-02-04T16:15:09.285818Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[y>1]=0\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d8f8bee91ce354f316e8ebb6d43f3a38d468c06e"
   },
   "source": [
    "# &#128295; Building Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3935f14daec0df6ff948054196c77fdf6a8d9196"
   },
   "source": [
    "##  Splitting the Dataset into the Training set and Test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "98ca8b335764e01df2b8aaa10183a4e577854d30",
    "execution": {
     "iopub.execute_input": "2023-02-04T16:15:56.522009Z",
     "iopub.status.busy": "2023-02-04T16:15:56.521650Z",
     "iopub.status.idle": "2023-02-04T16:15:56.702302Z",
     "shell.execute_reply": "2023-02-04T16:15:56.701539Z",
     "shell.execute_reply.started": "2023-02-04T16:15:56.521957Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "215e46fbe236162ccd3f551bdd4f58c4e13f30fd"
   },
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "7b5ac7857321848b984fbe95957e7078066daf75"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1de8aa4a8362c101e7bbd3a3376257dd7ed03a9f"
   },
   "source": [
    "# 1. Logistic Regression\n",
    "![Imgur](https://i.imgur.com/HyPUqwF.png)\n",
    "Logistic regression, or logit regression, or logit model is a regression model where the dependent variable (DV) is categorical. This article covers the case of a binary dependent variable—that is, where it can take only two values, \"0\" and \"1\", which represent outcomes such as pass/fail, win/lose, alive/dead or healthy/sick. Cases where the dependent variable has more than two outcome categories may be analysed in multinomial logistic regression, or, if the multiple categories are ordered, in ordinal logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "bb41b354adaf04dc6ce4a4a3204fe5bd8df629bc",
    "execution": {
     "iopub.execute_input": "2023-02-04T16:16:43.271471Z",
     "iopub.status.busy": "2023-02-04T16:16:43.270930Z",
     "iopub.status.idle": "2023-02-04T16:17:09.283726Z",
     "shell.execute_reply": "2023-02-04T16:17:09.282895Z",
     "shell.execute_reply.started": "2023-02-04T16:16:43.271260Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.25 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_log_reg = clf.predict(X_test)\n",
    "acc_log_reg = round(clf.score(X_train, y_train) * 100, 2)\n",
    "print (str(acc_log_reg) + ' %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0fc90f5ec9c604aaafa2de62e676556cf206292b"
   },
   "source": [
    "# 2.Support Vector Machine (SVM)\n",
    "![Imgur](https://i.imgur.com/HyPUqwF.png)\n",
    "Support Vector Machine (SVM) model is a Supervised Learning model used for classification and regression analysis. It is a representation of the examples as points in space, mapped so that the examples of the separate categories are divided by a clear gap that is as wide as possible. New examples are then mapped into that same space and predicted to belong to a category based on which side of the gap they fall.\n",
    "\n",
    "In addition to performing linear classification, SVMs can efficiently perform a non-linear classification using what is called the kernel trick, implicitly mapping their inputs into high-dimensional feature spaces. Suppose some given data points each belong to one of two classes, and the goal is to decide which class a new data point will be in. In the case of support vector machines, a data point is viewed as a  p -dimensional vector (a list of  p  numbers), and we want to know whether we can separate such points with a  (p−1) -dimensional hyperplane.\n",
    "\n",
    "When data are not labeled, supervised learning is not possible, and an unsupervised learning approach is required, which attempts to find natural clustering of the data to groups, and then map new data to these formed groups. The clustering algorithm which provides an improvement to the support vector machines is called support vector clustering and is often used in industrial applications either when data are not labeled or when only some data are labeled as a preprocessing for a classification pass.\n",
    "\n",
    "In the below code, SVC stands for Support Vector Classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "099f1945de2146e22b4cb0abbc5e128bdab827d3",
    "execution": {
     "iopub.execute_input": "2023-02-04T16:18:36.846561Z",
     "iopub.status.busy": "2023-02-04T16:18:36.846206Z",
     "iopub.status.idle": "2023-02-04T16:19:48.426881Z",
     "shell.execute_reply": "2023-02-04T16:19:48.426053Z",
     "shell.execute_reply.started": "2023-02-04T16:18:36.846502Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.33%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_svc = clf.predict(X_test)\n",
    "acc_svc = round(clf.score(X_train, y_train) * 100, 2)\n",
    "print (str(acc_svc) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f51852f983d909d7ed641c720e8e45064ebe3041"
   },
   "source": [
    "# Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "171a3d7c5beba58348c4a2c878ebf7dfe4f703c8",
    "execution": {
     "iopub.execute_input": "2023-02-04T16:20:05.430600Z",
     "iopub.status.busy": "2023-02-04T16:20:05.430256Z",
     "iopub.status.idle": "2023-02-04T16:20:12.047290Z",
     "shell.execute_reply": "2023-02-04T16:20:12.046225Z",
     "shell.execute_reply.started": "2023-02-04T16:20:05.430545Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc=82.45%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "clf = LinearSVC()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_linear_svc = clf.predict(X_test)\n",
    "acc_linear_svc = round(clf.score(X_train, y_train) * 100, 2)\n",
    "print (\"Acc=\"+ str(acc_linear_svc) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e7e214c66173633d35e15e637043b2aa4b782fe5"
   },
   "source": [
    "# 3.*k*-Nearest Neighbors\n",
    "![Imgur](https://i.imgur.com/HyPUqwF.png)\n",
    "*k* -nearest neighbors algorithm (k-NN) is one of the simplest machine learning algorithms and is used for classification and regression. In both cases, the input consists of the  k  closest training examples in the feature space. The output depends on whether  k -NN is used for classification or regression:\n",
    "\n",
    "* In  k -NN classification, the output is a class membership. An object is classified by a majority vote of its neighbors, with the object being assigned to the class most common among its  k  nearest neighbors ( k  is a positive integer, typically small). If  k=1 , then the object is simply assigned to the class of that single nearest neighbor.\n",
    "\n",
    "* In  k -NN regression, the output is the property value for the object. This value is the average of the values of its  k nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "93e7e59da21b3d12737061c6687cb628d0960dfb",
    "execution": {
     "iopub.execute_input": "2023-02-04T16:20:23.845710Z",
     "iopub.status.busy": "2023-02-04T16:20:23.845407Z",
     "iopub.status.idle": "2023-02-04T16:21:04.041098Z",
     "shell.execute_reply": "2023-02-04T16:21:04.040258Z",
     "shell.execute_reply.started": "2023-02-04T16:20:23.845656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.62%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_knn = clf.predict(X_test)\n",
    "acc_knn = round(clf.score(X_train, y_train) * 100, 2)\n",
    "print (str(acc_knn)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9f64a172f160a43d9ebd5f5ff988de9ba7084bb1"
   },
   "source": [
    "# 4. Gaussian Naive Bayes\n",
    "![Imgur](https://i.imgur.com/HyPUqwF.png)\n",
    "Naive Bayes classifiers are a family of simple probabilistic classifiers based on applying Bayes' theorem with strong (naive) independence assumptions between the features.\n",
    "\n",
    "Bayes' theorem (alternatively Bayes' law or Bayes' rule) describes the probability of an event, based on prior knowledge of conditions that might be related to the event. For example, if cancer is related to age, then, using Bayes' theorem, a person's age can be used to more accurately assess the probability that they have cancer, compared to the assessment of the probability of cancer made without knowledge of the person's age.\n",
    "\n",
    "Naive Bayes is a simple technique for constructing classifiers: models that assign class labels to problem instances, represented as vectors of feature values, where the class labels are drawn from some finite set. It is not a single algorithm for training such classifiers, but a family of algorithms based on a common principle: all naive Bayes classifiers assume that the value of a particular feature is independent of the value of any other feature, given the class variable. For example, a fruit may be considered to be an apple if it is red, round, and about 10 cm in diameter. A naive Bayes classifier considers each of these features to contribute independently to the probability that this fruit is an apple, regardless of any possible correlations between the color, roundness, and diameter features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "6090e8aa7daae6d6aef32152a077d867beef9d1b",
    "execution": {
     "iopub.execute_input": "2023-02-04T16:21:11.345665Z",
     "iopub.status.busy": "2023-02-04T16:21:11.345356Z",
     "iopub.status.idle": "2023-02-04T16:21:11.399379Z",
     "shell.execute_reply": "2023-02-04T16:21:11.398283Z",
     "shell.execute_reply.started": "2023-02-04T16:21:11.345612Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.79%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_gnb = clf.predict(X_test)\n",
    "acc_gnb = round(clf.score(X_train, y_train) * 100, 2)\n",
    "print (str(acc_gnb) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "724afa104f8fc061f379adb0ba408730e024abeb"
   },
   "source": [
    "# 5. Artificial Neural Networks(ANN)\n",
    "![Imgur](https://i.imgur.com/HyPUqwF.png)\n",
    "Computers are great at solving algorithmic and math problems, but often the world can't easily be defined with a mathematical algorithm. Facial recognition and language processing are a couple of examples of problems that can't easily be quantified into an algorithm, however these tasks are trivial to humans. The key to Artificial Neural Networks is that their design enables them to process information in a similar way to our own biological brains, by drawing inspiration from how our own nervous system functions. This makes them useful tools for solving problems like facial recognition, which our biological brains can do easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a62b3d36e974853cec28f77b5a195a24bf04f5f4"
   },
   "source": [
    "## Modeling Artificial Neurons\n",
    "Artificial neuron models are at their core simplified models based on biological neurons. This allows them to capture the essence of how a biological neuron functions. We usually refer to these artificial neurons as 'perceptrons'. So now lets take a look at what a perceptron looks like.\n",
    "![Imgur](https://i.imgur.com/uvMRQ6R.jpg)\n",
    "As shown in the diagram above a typical perceptron will have many inputs and these inputs are all individually weighted. The perceptron weights can either amplify or deamplify the original input signal. For example, if the input is 1 and the input's weight is 0.2 the input will be decreased to 0.2. These weighted signals are then added together and passed into the activation function. The activation function is used to convert the input into a more useful output. There are many different types of activation function but one of the simplest would be step function. A step function will typically output a 1 if the input is higher than a certain threshold, otherwise it's output will be 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "ef70904940d3a29a09db064e4264729878a88798",
    "execution": {
     "iopub.execute_input": "2023-02-04T16:21:26.101438Z",
     "iopub.status.busy": "2023-02-04T16:21:26.101065Z",
     "iopub.status.idle": "2023-02-04T16:21:26.466017Z",
     "shell.execute_reply": "2023-02-04T16:21:26.464944Z",
     "shell.execute_reply.started": "2023-02-04T16:21:26.101381Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Importing keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b1cb8e842cc4865e02f3cd620ed2d1ce36529876"
   },
   "source": [
    "## Implementing Artificial Neural Networks\n",
    "So now you're probably wondering what an artificial neural network looks like and how it uses these artificial neurons to process information. In this tutorial we're going to be looking at feedforward networks and how their design links our perceptron together creating a functioning artificial neural network. Before we begin lets take a look at what a basic feedforward network looks like:\n",
    "![Imgur](https://i.imgur.com/la4Rwn6.jpg)\n",
    "Each input from the input layer is fed up to each node in the hidden layer, and from there to each node on the output layer. We should note that there can be any number of nodes per layer and there are usually multiple hidden layers to pass through before ultimately reaching the output layer. Choosing the right number of nodes and layers is important later on when optimising the neural network to work well a given problem. As you can probably tell from the diagram, it's called a feedforward network because of how the signals are passed through the layers of the neural network in a single direction. These aren't the only type of neural network though. There are also feedback networks where its architecture allows signals to travel in both directions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "17903f4e7acd699e10feddda3f2ede2f122ba0d5"
   },
   "source": [
    "### Initializing the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "d5227ec581d362265d05d1ed25c12ac8f443464d",
    "execution": {
     "iopub.execute_input": "2023-02-04T16:21:44.497129Z",
     "iopub.status.busy": "2023-02-04T16:21:44.496791Z",
     "iopub.status.idle": "2023-02-04T16:21:44.502121Z",
     "shell.execute_reply": "2023-02-04T16:21:44.501249Z",
     "shell.execute_reply.started": "2023-02-04T16:21:44.497065Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4a9c01703ffd3ac194233a5e862225f3e010a80b"
   },
   "source": [
    "### Adding input layer and first hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "5cc825b56c5217cb6a39b696bc5f6e2552814d69",
    "execution": {
     "iopub.execute_input": "2023-02-04T16:21:56.915832Z",
     "iopub.status.busy": "2023-02-04T16:21:56.915508Z",
     "iopub.status.idle": "2023-02-04T16:21:56.940695Z",
     "shell.execute_reply": "2023-02-04T16:21:56.939772Z",
     "shell.execute_reply.started": "2023-02-04T16:21:56.915778Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=178, units=80, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(output_dim = 80, init = 'uniform', activation = 'relu', input_dim = 178))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a50585c8466e7c04739e18ae53cca8888282bce7"
   },
   "source": [
    "### Adding second hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "4d28df06df33846c0004b4461e7f67ef1bf78c5c",
    "execution": {
     "iopub.execute_input": "2023-02-04T16:22:04.781500Z",
     "iopub.status.busy": "2023-02-04T16:22:04.780980Z",
     "iopub.status.idle": "2023-02-04T16:22:04.801529Z",
     "shell.execute_reply": "2023-02-04T16:22:04.800751Z",
     "shell.execute_reply.started": "2023-02-04T16:22:04.781251Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=80, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(output_dim = 80, init = 'uniform', activation = 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b9b816ba42105e4d2d9f8ae465c59bc92eddd0b7"
   },
   "source": [
    "### Adding the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "b783f126f5845942a7fc9c46717cba4202527647",
    "execution": {
     "iopub.execute_input": "2023-02-04T16:22:13.695692Z",
     "iopub.status.busy": "2023-02-04T16:22:13.695371Z",
     "iopub.status.idle": "2023-02-04T16:22:13.716156Z",
     "shell.execute_reply": "2023-02-04T16:22:13.715134Z",
     "shell.execute_reply.started": "2023-02-04T16:22:13.695638Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "34352f3b099615aa9161cd4426ca522a91c4cf77"
   },
   "source": [
    "### Compiling the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "0b1f53b91b238b641147d384922834e0b562d6df",
    "execution": {
     "iopub.execute_input": "2023-02-04T16:22:18.859963Z",
     "iopub.status.busy": "2023-02-04T16:22:18.859658Z",
     "iopub.status.idle": "2023-02-04T16:26:32.244329Z",
     "shell.execute_reply": "2023-02-04T16:26:32.243688Z",
     "shell.execute_reply.started": "2023-02-04T16:22:18.859907Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9200/9200 [==============================] - 6s 629us/step - loss: 0.1890 - acc: 0.9516\n",
      "Epoch 2/100\n",
      "9200/9200 [==============================] - 2s 262us/step - loss: 0.0893 - acc: 0.9699\n",
      "Epoch 3/100\n",
      "9200/9200 [==============================] - 2s 259us/step - loss: 0.0682 - acc: 0.9775\n",
      "Epoch 4/100\n",
      "9200/9200 [==============================] - 2s 252us/step - loss: 0.0638 - acc: 0.9778\n",
      "Epoch 5/100\n",
      "9200/9200 [==============================] - 2s 251us/step - loss: 0.0573 - acc: 0.9790\n",
      "Epoch 6/100\n",
      "9200/9200 [==============================] - 3s 275us/step - loss: 0.0465 - acc: 0.9851\n",
      "Epoch 7/100\n",
      "9200/9200 [==============================] - 3s 274us/step - loss: 0.0438 - acc: 0.9829\n",
      "Epoch 8/100\n",
      "9200/9200 [==============================] - 3s 303us/step - loss: 0.0395 - acc: 0.9855\n",
      "Epoch 9/100\n",
      "9200/9200 [==============================] - 2s 255us/step - loss: 0.0369 - acc: 0.9872\n",
      "Epoch 10/100\n",
      "9200/9200 [==============================] - 3s 290us/step - loss: 0.0395 - acc: 0.9878\n",
      "Epoch 11/100\n",
      "9200/9200 [==============================] - 2s 259us/step - loss: 0.0293 - acc: 0.9885\n",
      "Epoch 12/100\n",
      "9200/9200 [==============================] - 2s 251us/step - loss: 0.0287 - acc: 0.9888\n",
      "Epoch 13/100\n",
      "9200/9200 [==============================] - 2s 252us/step - loss: 0.0229 - acc: 0.9920\n",
      "Epoch 14/100\n",
      "9200/9200 [==============================] - 2s 255us/step - loss: 0.0277 - acc: 0.9902\n",
      "Epoch 15/100\n",
      "9200/9200 [==============================] - 2s 272us/step - loss: 0.0221 - acc: 0.9926\n",
      "Epoch 16/100\n",
      "9200/9200 [==============================] - 2s 252us/step - loss: 0.0250 - acc: 0.9913\n",
      "Epoch 17/100\n",
      "9200/9200 [==============================] - 2s 249us/step - loss: 0.0173 - acc: 0.9945\n",
      "Epoch 18/100\n",
      "9200/9200 [==============================] - 2s 252us/step - loss: 0.0162 - acc: 0.9950\n",
      "Epoch 19/100\n",
      "9200/9200 [==============================] - 2s 256us/step - loss: 0.0187 - acc: 0.9945\n",
      "Epoch 20/100\n",
      "9200/9200 [==============================] - 3s 309us/step - loss: 0.0129 - acc: 0.9959\n",
      "Epoch 21/100\n",
      "9200/9200 [==============================] - 3s 289us/step - loss: 0.0189 - acc: 0.9936\n",
      "Epoch 22/100\n",
      "9200/9200 [==============================] - 2s 252us/step - loss: 0.0132 - acc: 0.9955\n",
      "Epoch 23/100\n",
      "9200/9200 [==============================] - 2s 253us/step - loss: 0.0119 - acc: 0.9963\n",
      "Epoch 24/100\n",
      "9200/9200 [==============================] - 3s 280us/step - loss: 0.0075 - acc: 0.9976\n",
      "Epoch 25/100\n",
      "9200/9200 [==============================] - 2s 252us/step - loss: 0.0167 - acc: 0.9946\n",
      "Epoch 26/100\n",
      "9200/9200 [==============================] - 2s 257us/step - loss: 0.0099 - acc: 0.9968\n",
      "Epoch 27/100\n",
      "9200/9200 [==============================] - 2s 257us/step - loss: 0.0118 - acc: 0.9972\n",
      "Epoch 28/100\n",
      "9200/9200 [==============================] - 2s 258us/step - loss: 0.0213 - acc: 0.9927\n",
      "Epoch 29/100\n",
      "9200/9200 [==============================] - 3s 272us/step - loss: 0.0058 - acc: 0.9982\n",
      "Epoch 30/100\n",
      "9200/9200 [==============================] - 2s 251us/step - loss: 0.0046 - acc: 0.9990\n",
      "Epoch 31/100\n",
      "9200/9200 [==============================] - 2s 253us/step - loss: 0.0180 - acc: 0.9957\n",
      "Epoch 32/100\n",
      "9200/9200 [==============================] - 2s 249us/step - loss: 0.0133 - acc: 0.9962\n",
      "Epoch 33/100\n",
      "9200/9200 [==============================] - 3s 297us/step - loss: 0.0120 - acc: 0.9959\n",
      "Epoch 34/100\n",
      "9200/9200 [==============================] - 3s 299us/step - loss: 0.0081 - acc: 0.9977\n",
      "Epoch 35/100\n",
      "9200/9200 [==============================] - 2s 253us/step - loss: 0.0046 - acc: 0.9985\n",
      "Epoch 36/100\n",
      "9200/9200 [==============================] - 2s 250us/step - loss: 0.0065 - acc: 0.9980\n",
      "Epoch 37/100\n",
      "9200/9200 [==============================] - 2s 250us/step - loss: 0.0121 - acc: 0.9967\n",
      "Epoch 38/100\n",
      "9200/9200 [==============================] - 3s 283us/step - loss: 0.0081 - acc: 0.9972\n",
      "Epoch 39/100\n",
      "9200/9200 [==============================] - 2s 250us/step - loss: 0.0039 - acc: 0.9987\n",
      "Epoch 40/100\n",
      "9200/9200 [==============================] - 2s 250us/step - loss: 0.0147 - acc: 0.9959\n",
      "Epoch 41/100\n",
      "9200/9200 [==============================] - 2s 248us/step - loss: 0.0025 - acc: 0.9995\n",
      "Epoch 42/100\n",
      "9200/9200 [==============================] - 3s 279us/step - loss: 0.0043 - acc: 0.9987\n",
      "Epoch 43/100\n",
      "9200/9200 [==============================] - 2s 254us/step - loss: 0.0161 - acc: 0.9951\n",
      "Epoch 44/100\n",
      "9200/9200 [==============================] - 2s 251us/step - loss: 0.0030 - acc: 0.9991\n",
      "Epoch 45/100\n",
      "9200/9200 [==============================] - 2s 251us/step - loss: 0.0049 - acc: 0.9991\n",
      "Epoch 46/100\n",
      "9200/9200 [==============================] - 2s 253us/step - loss: 6.4691e-04 - acc: 0.9999\n",
      "Epoch 47/100\n",
      "9200/9200 [==============================] - 3s 342us/step - loss: 7.8563e-04 - acc: 0.9998\n",
      "Epoch 48/100\n",
      "9200/9200 [==============================] - 2s 251us/step - loss: 0.0235 - acc: 0.9942\n",
      "Epoch 49/100\n",
      "9200/9200 [==============================] - 2s 250us/step - loss: 0.0129 - acc: 0.9959\n",
      "Epoch 50/100\n",
      "9200/9200 [==============================] - 2s 250us/step - loss: 0.0021 - acc: 0.9995\n",
      "Epoch 51/100\n",
      "9200/9200 [==============================] - 3s 284us/step - loss: 0.0013 - acc: 0.9997\n",
      "Epoch 52/100\n",
      "9200/9200 [==============================] - 2s 270us/step - loss: 0.0098 - acc: 0.9979\n",
      "Epoch 53/100\n",
      "9200/9200 [==============================] - 2s 264us/step - loss: 0.0166 - acc: 0.9960\n",
      "Epoch 54/100\n",
      "9200/9200 [==============================] - 2s 262us/step - loss: 0.0015 - acc: 0.9995\n",
      "Epoch 55/100\n",
      "9200/9200 [==============================] - 2s 251us/step - loss: 3.0735e-04 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "9200/9200 [==============================] - 3s 273us/step - loss: 1.8365e-04 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "9200/9200 [==============================] - 2s 251us/step - loss: 1.3396e-04 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "9200/9200 [==============================] - 2s 249us/step - loss: 4.8596e-04 - acc: 0.9998\n",
      "Epoch 59/100\n",
      "9200/9200 [==============================] - 2s 266us/step - loss: 0.0437 - acc: 0.9916\n",
      "Epoch 60/100\n",
      "9200/9200 [==============================] - 3s 323us/step - loss: 0.0046 - acc: 0.9980\n",
      "Epoch 61/100\n",
      "9200/9200 [==============================] - 2s 251us/step - loss: 0.0030 - acc: 0.9993\n",
      "Epoch 62/100\n",
      "9200/9200 [==============================] - 2s 253us/step - loss: 0.0023 - acc: 0.9992\n",
      "Epoch 63/100\n",
      "9200/9200 [==============================] - 2s 253us/step - loss: 0.0090 - acc: 0.9978\n",
      "Epoch 64/100\n",
      "9200/9200 [==============================] - 2s 249us/step - loss: 0.0162 - acc: 0.9957\n",
      "Epoch 65/100\n",
      "9200/9200 [==============================] - 3s 279us/step - loss: 0.0123 - acc: 0.9968\n",
      "Epoch 66/100\n",
      "9200/9200 [==============================] - 2s 249us/step - loss: 0.0014 - acc: 0.9995\n",
      "Epoch 67/100\n",
      "9200/9200 [==============================] - 2s 249us/step - loss: 0.0013 - acc: 0.9997\n",
      "Epoch 68/100\n",
      "9200/9200 [==============================] - 2s 255us/step - loss: 0.0043 - acc: 0.9983\n",
      "Epoch 69/100\n",
      "9200/9200 [==============================] - 2s 264us/step - loss: 0.0142 - acc: 0.9966\n",
      "Epoch 70/100\n",
      "9200/9200 [==============================] - 2s 265us/step - loss: 0.0104 - acc: 0.9978\n",
      "Epoch 71/100\n",
      "9200/9200 [==============================] - 2s 250us/step - loss: 0.0135 - acc: 0.9967\n",
      "Epoch 72/100\n",
      "9200/9200 [==============================] - 2s 250us/step - loss: 0.0031 - acc: 0.9993\n",
      "Epoch 73/100\n",
      "9200/9200 [==============================] - 3s 316us/step - loss: 0.0032 - acc: 0.9987\n",
      "Epoch 74/100\n",
      "9200/9200 [==============================] - 3s 279us/step - loss: 3.2580e-04 - acc: 0.9999\n",
      "Epoch 75/100\n",
      "9200/9200 [==============================] - 2s 247us/step - loss: 9.9687e-05 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "9200/9200 [==============================] - 2s 251us/step - loss: 7.1423e-05 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "9200/9200 [==============================] - 2s 252us/step - loss: 4.5841e-05 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "9200/9200 [==============================] - 2s 253us/step - loss: 0.0073 - acc: 0.9990\n",
      "Epoch 79/100\n",
      "9200/9200 [==============================] - 2s 267us/step - loss: 0.0349 - acc: 0.9926\n",
      "Epoch 80/100\n",
      "9200/9200 [==============================] - 2s 251us/step - loss: 0.0113 - acc: 0.9974\n",
      "Epoch 81/100\n",
      "9200/9200 [==============================] - 2s 251us/step - loss: 0.0050 - acc: 0.9984\n",
      "Epoch 82/100\n",
      "9200/9200 [==============================] - 2s 251us/step - loss: 5.2745e-04 - acc: 0.9999\n",
      "Epoch 83/100\n",
      "9200/9200 [==============================] - 3s 278us/step - loss: 6.4827e-04 - acc: 0.9999\n",
      "Epoch 84/100\n",
      "9200/9200 [==============================] - 2s 249us/step - loss: 0.0061 - acc: 0.9987\n",
      "Epoch 85/100\n",
      "9200/9200 [==============================] - 2s 250us/step - loss: 0.0043 - acc: 0.9980\n",
      "Epoch 86/100\n",
      "9200/9200 [==============================] - 3s 316us/step - loss: 0.0074 - acc: 0.9978\n",
      "Epoch 87/100\n",
      "9200/9200 [==============================] - 2s 250us/step - loss: 0.0047 - acc: 0.9985\n",
      "Epoch 88/100\n",
      "9200/9200 [==============================] - 3s 283us/step - loss: 0.0020 - acc: 0.9993\n",
      "Epoch 89/100\n",
      "9200/9200 [==============================] - 2s 251us/step - loss: 0.0049 - acc: 0.9983\n",
      "Epoch 90/100\n",
      "9200/9200 [==============================] - 2s 248us/step - loss: 0.0033 - acc: 0.9990\n",
      "Epoch 91/100\n",
      "9200/9200 [==============================] - 2s 248us/step - loss: 0.0015 - acc: 0.9996\n",
      "Epoch 92/100\n",
      "9200/9200 [==============================] - 3s 285us/step - loss: 0.0123 - acc: 0.9967\n",
      "Epoch 93/100\n",
      "9200/9200 [==============================] - 2s 270us/step - loss: 0.0133 - acc: 0.9974\n",
      "Epoch 94/100\n",
      "9200/9200 [==============================] - 2s 261us/step - loss: 0.0030 - acc: 0.9989\n",
      "Epoch 95/100\n",
      "9200/9200 [==============================] - 2s 252us/step - loss: 0.0058 - acc: 0.9991\n",
      "Epoch 96/100\n",
      "9200/9200 [==============================] - 2s 254us/step - loss: 9.8194e-05 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "9200/9200 [==============================] - 3s 277us/step - loss: 3.9153e-05 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "9200/9200 [==============================] - 2s 252us/step - loss: 3.0572e-05 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "9200/9200 [==============================] - 3s 309us/step - loss: 2.2075e-05 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "9200/9200 [==============================] - 2s 249us/step - loss: 1.6556e-05 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc829724fd0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "#Fitting the ANN to the training set\n",
    "classifier.fit(X_train, y_train, batch_size = 10, nb_epoch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "d6d20a37e919957eca21406a579f230c69dddf4d",
    "execution": {
     "iopub.execute_input": "2023-02-04T16:31:12.750769Z",
     "iopub.status.busy": "2023-02-04T16:31:12.750446Z",
     "iopub.status.idle": "2023-02-04T16:31:12.843789Z",
     "shell.execute_reply": "2023-02-04T16:31:12.842240Z",
     "shell.execute_reply.started": "2023-02-04T16:31:12.750714Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.79%\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "acc_ANN = round(clf.score(X_train, y_train) * 100, 2)\n",
    "print (str(acc_ANN) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6ca8da32b15bea0d9a05d29b2b870e7b5e3d6f8c"
   },
   "source": [
    "# Principal Component Analysis (PCA)\n",
    "![Imgur](https://i.imgur.com/HyPUqwF.png)\n",
    "Principal\tComponent\tAnalysis\t(PCA)is a dimension-reduction tool that can be used to reduce a large set of variables to a small set that still contains most of the information in the large set.\n",
    "\n",
    "How does PCA work -\n",
    "\n",
    "1. Calculate the covariance matrix X of data points.\n",
    "2. Calculate eigen vectors and corresponding eigen values.\n",
    "3. Sort the eigen vectors according to their eigen values in decreasing order.\n",
    "4. Choose first k eigen vectors and that will be the new k dimensions.\n",
    "5. Transform the original n dimensional data points into k dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "61a34e727af945a625193d25df16c3941e451cf7",
    "execution": {
     "iopub.execute_input": "2023-02-04T16:31:19.380504Z",
     "iopub.status.busy": "2023-02-04T16:31:19.380163Z",
     "iopub.status.idle": "2023-02-04T16:31:19.697483Z",
     "shell.execute_reply": "2023-02-04T16:31:19.694880Z",
     "shell.execute_reply.started": "2023-02-04T16:31:19.380447Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "acc_PCA = round(pca.score(X_train, y_train) )\n",
    "print (str(acc_PCA) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "572251b49c99a3c6e27d0945cb9fcc53e7a29662"
   },
   "source": [
    "# Comparing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "646bccff6126c0b579594a3217c0fa045473abfd",
    "execution": {
     "iopub.execute_input": "2023-02-04T16:31:32.935133Z",
     "iopub.status.busy": "2023-02-04T16:31:32.934807Z",
     "iopub.status.idle": "2023-02-04T16:31:32.951650Z",
     "shell.execute_reply": "2023-02-04T16:31:32.950324Z",
     "shell.execute_reply.started": "2023-02-04T16:31:32.935066Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Support Vector Machines</td>\n",
       "      <td>98.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANN</td>\n",
       "      <td>95.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>95.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>93.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Principal Component Analysis</td>\n",
       "      <td>90.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>82.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model  Score\n",
       "1       Support Vector Machines  98.33\n",
       "2                           ANN  95.79\n",
       "4                   Naive Bayes  95.79\n",
       "3                           KNN  93.62\n",
       "5  Principal Component Analysis  90.00\n",
       "0           Logistic Regression  82.25"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Support Vector Machines','ANN', \n",
    "              'KNN', 'Naive Bayes', 'Principal Component Analysis'],\n",
    "    \n",
    "    'Score': [acc_log_reg, acc_svc,acc_ANN , \n",
    "              acc_knn, acc_gnb,acc_PCA ]\n",
    "    })\n",
    "\n",
    "models.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a53f723605eb5f1852bb9b094ebba1d6fe035f3c"
   },
   "source": [
    "# Conclusion\n",
    "The aim of this study is to detect epileptic seizure using two different feature ex-traction methods and comparison performance of various machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EEG EPILIPTIC : FINISH**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
